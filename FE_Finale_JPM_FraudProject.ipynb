{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c93732",
   "metadata": {},
   "source": [
    "I removed some of the graph and featueres calculated in FraudFeatureEngineer I found that those features were the problem. They were leaking information future information into the present.  For example: Given everything up to December, here's what October's fraud behavior looks like. So leakage was coming from the way we are calculating features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7287c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import community as community_louvain\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d511df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/noimotbakare/Dropbox/Fraud_Payments/data/fraud_payment_data', sep=',', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed97a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting time into a Datetime object\n",
    "df['timestamp'] = pd.to_datetime(df['Time_step'])\n",
    "#Removing redudant columns\n",
    "df=df.drop('Time_step',axis=1)\n",
    "df=df.drop('Sender_lob',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a03664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineering Features that do not rely on Statistics before train test split\n",
    "\n",
    "#First Digit \n",
    "df['USD_amount'] = pd.to_numeric(df['USD_amount'], errors='coerce')\n",
    "#Extract the first digit from each amount\n",
    "df['first_digit'] = df['USD_amount'].astype(str).str.strip().str[0]\n",
    "df = df[df['first_digit'].str.isdigit()]\n",
    "df['first_digit'] = df['first_digit'].astype(int)\n",
    "\n",
    "#Last Digit \n",
    "#Extract the last digit after decimal USD_amount\n",
    "df['last_digit_after_dec'] = df['USD_amount'].astype(str).str.split('.').str[1].str[-1]\n",
    "df = df[df['last_digit_after_dec'].str.isdigit()]\n",
    "df['last_digit_after_dec'] = df['last_digit_after_dec'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7468da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.sort_values('timestamp') #( I know the data may be sorted, but I like to cross my t's and dot my i's.)\n",
    "split_date = df['timestamp'].quantile(0.80)\n",
    "\n",
    "train_full = df[df['timestamp'] <= split_date].copy()\n",
    "#future set test set \n",
    "df_test = df[df['timestamp'] > split_date].copy()\n",
    "\n",
    "#stratifying to address class imbalance \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    train_full,\n",
    "    #20% of train_full becomes validation\n",
    "    test_size=0.20,  \n",
    "    #stratifying on fraud \n",
    "    stratify=train_full['Label'], #I know we said the data has done a good job splititng but again ^\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a7591",
   "metadata": {},
   "source": [
    "Sorting and Stratifying although the data is sorted for best practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0f35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sort_values('timestamp') #( I know the data may be sorted, but I like to cross my t's and dot my i's.)\n",
    "split_date = df['timestamp'].quantile(0.80)\n",
    "\n",
    "train_full = df[df['timestamp'] <= split_date].copy()\n",
    "#future set test set \n",
    "df_test = df[df['timestamp'] > split_date].copy()\n",
    "\n",
    "#stratifying to address class imbalance \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    train_full,\n",
    "    #20% of train_full becomes validation\n",
    "    test_size=0.20,  \n",
    "    #stratifying on fraud \n",
    "    stratify=train_full['Label'], #I know we said the data has done a good job splititng but again ^\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a71438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of fraud for the train data is:\n",
      " Label\n",
      "0    0.979287\n",
      "1    0.020713\n",
      "Name: proportion, dtype: float64\n",
      "The distribution of fraud for the validation set is:\n",
      " Label\n",
      "0    0.979287\n",
      "1    0.020713\n",
      "Name: proportion, dtype: float64\n",
      "The distribution of fraud for the test set is:\n",
      " Label\n",
      "0    0.979996\n",
      "1    0.020004\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the distribution of fraudulent/legitimate transactions are consistent across the three different sets.\n",
    "print('The distribution of fraud for the train data is:\\n', df_train['Label'].value_counts(normalize=True))\n",
    "print('The distribution of fraud for the validation set is:\\n', df_val['Label'].value_counts(normalize=True))\n",
    "print('The distribution of fraud for the test set is:\\n', df_test['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f944c5",
   "metadata": {},
   "source": [
    "1. Rolling sender/beneficiary behavior √\n",
    "filled large numbers with 99999\n",
    "filled NaN with 0 because it means \n",
    "\n",
    "here I also calculate 'sender_last_time_diff' - that is the sudden burst - how much time passed since the sender's previous transaction\n",
    "\n",
    "2. One-hot encode Transaction Type √\n",
    "\n",
    "3. Lagged target encoding (fraud rates) √\n",
    "Lagged target encoding (fraud rates) -  computing historical fraud rates for an entity up to but not including the current transaction.\n",
    "\n",
    "This answers the quesrion What was the fraud rate for this sender / country / sector before this transaction?\n",
    "\n",
    "4. Time aware country/sector behavior √\n",
    "Initially I calculated: \n",
    "Country_Fraud_Ratio (lifetime or globally)\n",
    "Sector_Fraud_Ratio (lifetime) \n",
    "\n",
    "Here we look at:\n",
    "country mean fraud rate -  in this country over last N transactions, BEFORE this one\n",
    "sector mean fraud rate - in this sector over last N transactions, BEFORE this one\n",
    "\n",
    "5. Incremental Network Fraud Signals \n",
    "(I do not use Louvain or NX - if anyone wants to give it a try - I just want to keep things clean in hopes we get some results). So this asks if and how fast does fraud spread through a network\n",
    "\n",
    "6. Tomorrow I may try this-  We can look at how a user's network changes overtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a811b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "class FraudFeatureEngineer_TimeAware(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, windows=[7,30], te_window=200):\n",
    "        self.windows = windows\n",
    "        self.te_window = te_window\n",
    "        self.fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def _create_rolling_features(self, df):\n",
    "        df = df.sort_values('timestamp').copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['ts'] = df['timestamp']\n",
    "\n",
    "#---------\n",
    "#Tx features - rolling w= 7, 30, 90 days - how many transactions this sender made in the past w days, before the current one.\n",
    "#---------\n",
    "        for w in self.windows:\n",
    "            window = f\"{w}d\"\n",
    "\n",
    "            df[f\"sender_tx_count_{w}d\"] = (\n",
    "                df.groupby('Sender_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "\n",
    "            df[f\"sender_tx_mean_{w}d\"] = (\n",
    "                df.groupby('Sender_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "\n",
    "            df[f\"sender_tx_std_{w}d\"] = (\n",
    "                df.groupby('Sender_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "\n",
    "            df[f\"bene_tx_count_{w}d\"] = (\n",
    "                df.groupby('Bene_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "\n",
    "            df[f\"bene_tx_mean_{w}d\"] = (\n",
    "                df.groupby('Bene_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "\n",
    "            df[f\"bene_tx_std_{w}d\"] = (\n",
    "                df.groupby('Bene_Account')\n",
    "                  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
    "                  .reset_index(level=0, drop=True)\n",
    "                  .fillna(0)\n",
    "            )\n",
    "            \n",
    "#Sender last time - how much time passed since the sender's previous transaction\n",
    "#sudden burst\n",
    "        df['sender_last_time_diff'] = (\n",
    "            df.groupby('Sender_Account')['ts']\n",
    "              .diff()\n",
    "              .dt.total_seconds()\n",
    "              .shift(1)\n",
    "              .fillna(999999)\n",
    "        )\n",
    "\n",
    "        df = df.drop(columns=['ts'])\n",
    "        return df\n",
    "\n",
    "#------------ \n",
    "#Lagged features \n",
    "#--------------\n",
    "    def _add_lagged_target_encoding(self, df):\n",
    "        df = df.sort_values([\"timestamp\"])\n",
    "\n",
    "        df[\"sender_fraud_rate\"] = (\n",
    "            df.groupby(\"Sender_Account\")[\"Label\"]\n",
    "              .rolling(window=self.te_window, min_periods=1)\n",
    "              .mean()\n",
    "              .shift(1)\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        df[\"country_fraud_rate\"] = (\n",
    "            df.groupby(\"Sender_Country\")[\"Label\"]\n",
    "              .rolling(window=self.te_window, min_periods=1)\n",
    "              .mean()\n",
    "              .shift(1)\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        df[\"sector_fraud_rate\"] = (\n",
    "            df.groupby(\"Sender_Sector\")[\"Label\"]\n",
    "              .rolling(window=self.te_window, min_periods=1)\n",
    "              .mean()\n",
    "              .shift(1)\n",
    "              .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    " #-----------\n",
    " # Incremental Graph Fraud Features      \n",
    " #--------------------------------\n",
    "    #Does fraud spread through the network overtime? how fast?\n",
    "    def _add_incremental_graph_features(self, df):\n",
    "        df = df.sort_values(\"timestamp\").copy()\n",
    "         #dynamic neighbors\n",
    "        neighbors = defaultdict(set)\n",
    "\n",
    "        #features\n",
    "        fraud_neighbors_count = []\n",
    "        fraud_neighbors_rate = []\n",
    "        connected_to_fraud = []\n",
    "\n",
    "        #rolling fraud (memory)\n",
    "        recent_frauds = defaultdict(list)\n",
    "        window_days = 30\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            s = row[\"Sender_Account\"]\n",
    "            b = row[\"Bene_Account\"]\n",
    "            t = row[\"timestamp\"]\n",
    "            #alright so we want the neighbors seen before \"this\" transasction\n",
    "            neighbor_set = neighbors[s] | neighbors[b]\n",
    "\n",
    "            #Valid frauds - will be frauds within said time window \n",
    "            valid_frauds = [ts for ts in recent_frauds[s] + recent_frauds[b] if (t - ts).days <= window_days]\n",
    "\n",
    "            fraud_neighbors_count.append(len(valid_frauds))\n",
    "            connected_to_fraud.append(1 if len(valid_frauds) > 0 else 0)\n",
    "            \n",
    "            #rate = count/total neightbors \n",
    "            fraud_neighbors_rate.append(len(valid_frauds) / max(1, len(neighbor_set)))\n",
    "            #this line update the neighbor graph after the features are recorded\n",
    "            neighbors[s].add(b)\n",
    "            neighbors[s].add(b)\n",
    "            neighbors[b].add(s)\n",
    "\n",
    "            #if fraud - then record for future use \n",
    "            if row[\"Label\"] == 1:\n",
    "                recent_frauds[s].append(t)\n",
    "                recent_frauds[b].append(t)\n",
    "\n",
    "        df[\"fraud_neighbors_count_30d\"] = fraud_neighbors_count\n",
    "        df[\"fraud_neighbors_rate_30d\"] = fraud_neighbors_rate\n",
    "        df[\"connected_to_fraud_30d\"] = connected_to_fraud\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not self.fitted_:\n",
    "            raise RuntimeError(\"Call fit() first.\")\n",
    "\n",
    "        df = X.copy()\n",
    "\n",
    "        df = self._create_rolling_features(df)\n",
    "        df = self._add_lagged_target_encoding(df)\n",
    "        df = self._add_incremental_graph_features(df)\n",
    "\n",
    "        df = df.fillna(0)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f1f4e",
   "metadata": {},
   "source": [
    "This takes a little less than 30minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb12e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:44: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].count().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].mean().shift(1))\n",
      "/var/folders/4z/15wr09ws2bv_y9y731bmm5540000gn/T/ipykernel_64677/3785888919.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.rolling(window, on='ts')['USD_amount'].std().shift(1))\n"
     ]
    }
   ],
   "source": [
    "fe = FraudFeatureEngineer_TimeAware(windows=[7, 30], te_window=200)\n",
    "\n",
    "fe.fit(df_train)\n",
    "\n",
    "df_train_transformed = fe.transform(df_train)\n",
    "df_val_transformed = fe.transform(df_val)\n",
    "df_test_transformed = fe.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f31447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = df_train_transformed.fillna(0)\n",
    "df_val_transformed   = df_val_transformed.fillna(0)\n",
    "df_test_transformed  = df_test_transformed.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24d5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Encoding transaction type\n",
    "\n",
    "cat_cols = [\"Transaction_Type\"]\n",
    "df_train_transformed = pd.get_dummies(df_train_transformed, columns=cat_cols)\n",
    "df_val_transformed   = pd.get_dummies(df_val_transformed,   columns=cat_cols)\n",
    "df_test_transformed  = pd.get_dummies(df_test_transformed,  columns=cat_cols)\n",
    "\n",
    "# align columns (val/test may be missing categories)\n",
    "df_val_transformed  = df_val_transformed.reindex(columns=df_train_transformed.columns, fill_value=0)\n",
    "df_test_transformed = df_test_transformed.reindex(columns=df_train_transformed.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb0d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency encoding sender sector and country\n",
    "for col in [\"Sender_Country\", \"Sender_Sector\"]:\n",
    "    freq = df_train_transformed[col].value_counts()\n",
    "    df_train_transformed[f\"{col}_freq\"] = df_train_transformed[col].map(freq)\n",
    "    df_val_transformed[f\"{col}_freq\"]   = df_val_transformed[col].map(freq).fillna(0)\n",
    "    df_test_transformed[f\"{col}_freq\"]  = df_test_transformed[col].map(freq).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07647fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train_transformed['Label']\n",
    "y_val   = df_val_transformed['Label']\n",
    "y_test  = df_test_transformed['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aa058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = df_train_transformed.drop(columns=['Label'])\n",
    "df_val_transformed   = df_val_transformed.drop(columns=['Label'])\n",
    "df_test_transformed  = df_test_transformed.drop(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "243cd1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transaction_Id', 'Sender_Id', 'Sender_Account', 'Sender_Country',\n",
       "       'Sender_Sector', 'Bene_Id', 'Bene_Account', 'Bene_Country',\n",
       "       'USD_amount', 'timestamp', 'first_digit', 'last_digit_after_dec',\n",
       "       'sender_tx_count_7d', 'sender_tx_mean_7d', 'sender_tx_std_7d',\n",
       "       'bene_tx_count_7d', 'bene_tx_mean_7d', 'bene_tx_std_7d',\n",
       "       'sender_tx_count_30d', 'sender_tx_mean_30d', 'sender_tx_std_30d',\n",
       "       'bene_tx_count_30d', 'bene_tx_mean_30d', 'bene_tx_std_30d',\n",
       "       'sender_last_time_diff', 'sender_fraud_rate', 'country_fraud_rate',\n",
       "       'sector_fraud_rate', 'fraud_neighbors_count_30d',\n",
       "       'fraud_neighbors_rate_30d', 'connected_to_fraud_30d',\n",
       "       'Transaction_Type_DEPOSIT-CASH', 'Transaction_Type_DEPOSIT-CHECK',\n",
       "       'Transaction_Type_EXCHANGE', 'Transaction_Type_MAKE-PAYMENT',\n",
       "       'Transaction_Type_MOVE-FUNDS', 'Transaction_Type_PAY-CHECK',\n",
       "       'Transaction_Type_QUICK-PAYMENT', 'Transaction_Type_WITHDRAWAL',\n",
       "       'Sender_Country_freq', 'Sender_Sector_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the list of columns in df \n",
    "df_train_transformed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9a4ff",
   "metadata": {},
   "source": [
    "X_rolling are non network features, and X_rolling_nx includes networkfeatures. \n",
    "NOTE: The network calculation do not involve graph network.These are manual calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c5805",
   "metadata": {},
   "source": [
    "Lets check out the performance of the features before addinf network features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7d22698",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rolling = [\n",
    "'USD_amount', \n",
    " #Benford\n",
    "'first_digit',\n",
    "'last_digit_after_dec', \n",
    "\n",
    "#Rolling sender Bene behavior \n",
    "'sender_tx_count_7d',\n",
    "'sender_tx_mean_7d',\n",
    "'sender_tx_std_7d',\n",
    "'bene_tx_count_7d',\n",
    "'bene_tx_mean_7d',\n",
    "'bene_tx_std_7d',\n",
    "'sender_tx_count_30d',\n",
    "'sender_tx_mean_30d',\n",
    "'sender_tx_std_30d', \n",
    "'bene_tx_count_30d', \n",
    "'bene_tx_mean_30d',\n",
    "'bene_tx_std_30d', \n",
    "'sender_last_time_diff', \n",
    "\n",
    "\n",
    "##One Hot Encoding Transaction type \n",
    "'Transaction_Type_DEPOSIT-CASH', \n",
    "'Transaction_Type_DEPOSIT-CHECK',\n",
    "'Transaction_Type_EXCHANGE', \n",
    "'Transaction_Type_MAKE-PAYMENT',\n",
    "'Transaction_Type_MOVE-FUNDS', \n",
    "'Transaction_Type_PAY-CHECK',\n",
    "'Transaction_Type_QUICK-PAYMENT', \n",
    "'Transaction_Type_WITHDRAWAL',\n",
    "\n",
    "#Fraud rate\n",
    "#What was the fraud rate for this sender / country / sector before this transaction?\n",
    "'sender_fraud_rate',\n",
    "'country_fraud_rate', \n",
    "'sector_fraud_rate',\n",
    "\n",
    "#frequency encoding sector and counrty\n",
    "'Sender_Country_freq',\n",
    "'Sender_Sector_freq'\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1247b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does not include network explanatory features \n",
    "X_train = df_train_transformed[X_rolling]\n",
    "X_val   = df_val_transformed[X_rolling]\n",
    "X_test  = df_test_transformed[X_rolling]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "128cce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "#Apply the same scaling to validation and test sets\n",
    "X_val= scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e3d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation ROC-AUC: 0.6682\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.82    234744\n",
      "           1       0.04      0.53      0.07      4965\n",
      "\n",
      "    accuracy                           0.69    239709\n",
      "   macro avg       0.51      0.61      0.44    239709\n",
      "weighted avg       0.97      0.69      0.80    239709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finally!!!!!!!!! Run Logistic Baseline Model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "#Instantiate the model\n",
    "#Using class_weight='balanced' to handle known fraud data imbalanc\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "\n",
    "#Train the model on the SCALED training data - because Logistic regression is sensetive to scale ( won't need this for XGBoost)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_val_proba_lr = log_reg.predict_proba(X_val)[:, 1]\n",
    "\n",
    "lr_auc = roc_auc_score(y_val, y_val_proba_lr)\n",
    "print(f\"Logistic Regression Validation ROC-AUC: {lr_auc:.4f}\")\n",
    "\n",
    "y_val_pred_lr = log_reg.predict(X_val)\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "\n",
    "print(classification_report(y_val, y_val_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1a217f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation ROC-AUC: 0.7354\n",
      "XGBoost Validation PR-AUC: 0.1163\n",
      "\n",
      "Classification Report @ 0.50 threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9864    0.8201    0.8956    234744\n",
      "           1     0.0517    0.4634    0.0930      4965\n",
      "\n",
      "    accuracy                         0.8127    239709\n",
      "   macro avg     0.5190    0.6418    0.4943    239709\n",
      "weighted avg     0.9670    0.8127    0.8790    239709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute scale_pos_weight for imbalance\n",
    "scale_pos_weight_value = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "# XGBoost model tuned for fraud imbalance\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight = scale_pos_weight_value, \n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_val_proba_xgb = xgb.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Baseline 0.50 threshold predictions\n",
    "y_val_pred_xgb = (y_val_proba_xgb >= 0.50).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba_xgb)\n",
    "pr_auc  = average_precision_score(y_val, y_val_proba_xgb)\n",
    "\n",
    "print(f\"XGBoost Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"XGBoost Validation PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report @ 0.50 threshold:\")\n",
    "print(classification_report(y_val, y_val_pred_xgb, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a572a",
   "metadata": {},
   "source": [
    "Now we work with the df with the network features \n",
    "\n",
    "#Fraud Neighbors ( network features)\n",
    "'fraud_neighbors_count_30d',\n",
    "'fraud_neighbors_rate_30d',\n",
    "'connected_to_fraud_30d',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "396fd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx here just means network\n",
    "X_rolling_w_nx = [\n",
    "'USD_amount', \n",
    " #Benford\n",
    "'first_digit',\n",
    "'last_digit_after_dec', \n",
    "\n",
    "#Rolling sender Bene behavior \n",
    "'sender_tx_count_7d',\n",
    "'sender_tx_mean_7d',\n",
    "'sender_tx_std_7d',\n",
    "'bene_tx_count_7d',\n",
    "'bene_tx_mean_7d',\n",
    "'bene_tx_std_7d',\n",
    "'sender_tx_count_30d',\n",
    "'sender_tx_mean_30d',\n",
    "'sender_tx_std_30d', \n",
    "'bene_tx_count_30d', \n",
    "'bene_tx_mean_30d',\n",
    "'bene_tx_std_30d', \n",
    "'sender_last_time_diff', \n",
    "\n",
    "\n",
    "\n",
    "##One Hot Encoding Transaction type \n",
    "'Transaction_Type_DEPOSIT-CASH', \n",
    "'Transaction_Type_DEPOSIT-CHECK',\n",
    "'Transaction_Type_EXCHANGE', \n",
    "'Transaction_Type_MAKE-PAYMENT',\n",
    "'Transaction_Type_MOVE-FUNDS', \n",
    "'Transaction_Type_PAY-CHECK',\n",
    "'Transaction_Type_QUICK-PAYMENT', \n",
    "'Transaction_Type_WITHDRAWAL',\n",
    "\n",
    "#Fraud rate\n",
    "#What was the fraud rate for this sender / country / sector before this transaction?\n",
    "'sender_fraud_rate',\n",
    "'country_fraud_rate', \n",
    "'sector_fraud_rate',\n",
    "\n",
    "#Fraud Neighbors ( network features)\n",
    "'fraud_neighbors_count_30d',\n",
    "'fraud_neighbors_rate_30d',\n",
    "'connected_to_fraud_30d',\n",
    "\n",
    "#frequency encoding sector and counrty\n",
    "'Sender_Country_freq',\n",
    "'Sender_Sector_freq'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59615066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network explanatory features \n",
    "X_train_nx = df_train_transformed[X_rolling_w_nx]\n",
    "X_val_nx   = df_val_transformed[X_rolling_w_nx]\n",
    "X_test_nx  = df_test_transformed[X_rolling_w_nx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab977b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize scaler on the training data for Network explanatory features \n",
    "scaler = StandardScaler()\n",
    "X_train_nx = scaler.fit_transform(X_train_nx)\n",
    "\n",
    "#Apply the same scaling to validation and test sets\n",
    "X_val_nx = scaler.transform(X_val_nx)\n",
    "X_test_nx = scaler.transform(X_test_nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b7b2e",
   "metadata": {},
   "source": [
    "Logistic regression using network triaing and validation dfs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c7f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nx:Logistic Regression Validation ROC-AUC: 0.6682\n",
      "\n",
      "Nx:Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87    234744\n",
      "           1       0.05      0.49      0.08      4965\n",
      "\n",
      "    accuracy                           0.78    239709\n",
      "   macro avg       0.52      0.64      0.48    239709\n",
      "weighted avg       0.97      0.78      0.86    239709\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #Logistic Baseline Model for nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "#Instantiate the model\n",
    "#Using class_weight='balanced' to handle known fraud data imbalanc\n",
    "log_reg_nx = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "\n",
    "#Train the model on the SCALED training data - because Logistic regression is sensetive to scale ( won't need this for XGBoost)\n",
    "log_reg_nx.fit(X_train_nx, y_train)\n",
    "\n",
    "y_val_proba_lr_nx = log_reg_nx.predict_proba(X_val_nx)[:, 1]\n",
    "\n",
    "lr_auc_nx = roc_auc_score(y_val, y_val_proba_lr)\n",
    "print(f\"Nx:Logistic Regression Validation ROC-AUC: {lr_auc:.4f}\")\n",
    "\n",
    "y_val_pred_lr_nx = log_reg_nx.predict(X_val_nx)\n",
    "print(\"\\nNx:Validation Classification Report:\")\n",
    "\n",
    "print(classification_report(y_val, y_val_pred_lr_nx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07904dfb",
   "metadata": {},
   "source": [
    "XGB using network training and validation dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6420a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation ROC-AUC: 0.7683\n",
      "XGBoost Validation PR-AUC: 0.1342\n",
      "\n",
      "Classification Report @ 0.50 threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9872    0.8778    0.9293    234744\n",
      "           1     0.0742    0.4632    0.1280      4965\n",
      "\n",
      "    accuracy                         0.8692    239709\n",
      "   macro avg     0.5307    0.6705    0.5286    239709\n",
      "weighted avg     0.9683    0.8692    0.9127    239709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute scale_pos_weight for imbalance\n",
    "scale_pos_weight_value = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "# XGBoost model tuned for fraud imbalance\n",
    "xgb_nx = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8, \n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight = scale_pos_weight_value, \n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_nx.fit(X_train_nx, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_val_proba_xgb_nx = xgb_nx.predict_proba(X_val_nx)[:,1]\n",
    "\n",
    "# Baseline 0.50 threshold predictions\n",
    "y_val_pred_xgb_nx = (y_val_proba_xgb_nx >= 0.50).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc_nx = roc_auc_score(y_val, y_val_proba_xgb_nx)\n",
    "pr_auc_nx = average_precision_score(y_val, y_val_proba_xgb_nx)\n",
    "\n",
    "print(f\"XGBoost Validation ROC-AUC: {roc_auc_nx:.4f}\")\n",
    "print(f\"XGBoost Validation PR-AUC: {pr_auc_nx:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report @ 0.50 threshold:\")\n",
    "print(classification_report(y_val, y_val_pred_xgb_nx, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdec66e",
   "metadata": {},
   "source": [
    "Next steps: \n",
    "\n",
    "1. Track how a user’s network changes over time (will take the code longer to run)\n",
    "2. We can play with the threshold to \n",
    "3. Try optimizing \n",
    "4. Test how much each feature contributes model prediction. \n",
    "5. LightGBM\n",
    "6. SMOTE \n",
    "7. Random forest \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
