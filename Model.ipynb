{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5581249-e59e-458b-a0b2-19520deecdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, log_loss,average_precision_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6a69f-1434-40df-8f42-6232abf4e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv('fraud_payment_data', sep=',', header=0) \n",
    "final_features=pd.read_csv('total_features', sep=',', header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2b5b9-b328-4b2a-9ae5-d83467bf3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=total_data[total_data.USD_amount>0]\n",
    "total_data=total_data.reset_index(drop=True)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb72d0-0af1-44cc-ab76-af9c7a3c1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07edad91-247d-447d-92c8-de184ccd92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model testing without accounting for class imbalance\n",
    "log_reg = LogisticRegression(penalty=None)\n",
    "xgb=XGBClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "X=StandardScaler().fit_transform(train_features.values)\n",
    "## fit the model\n",
    "rf.fit(X,y_train)\n",
    "xgb.fit(X,y_train)\n",
    "log_reg.fit(X,y_train)\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d31d5-ec61-4643-ac5c-b1b1a6681649",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=final_features[0:1000000]\n",
    "validate_features=final_features[1000000:1250000]\n",
    "test_features=final_features[1250000:-1]\n",
    "\n",
    "y_train=total_data['Label'][0:1000000]\n",
    "y_validate=total_data['Label'][1000000:1250000]\n",
    "y_test=total_data['Label'][1250000:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5c1f8-357a-4540-a367-640c33024f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Validation\n",
    "cutoff = 0.1\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(validate_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_validate)/len(y_validate), \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9beba-5dec-4bd0-9e87-7c707dd2c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "cutoff = 0.1\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(test_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_test)/len(y_test), \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a10789-93b0-47e1-a5cd-961dfed5e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using SMOTE for handling class imbalance\n",
    "smote=SMOTE()\n",
    "X_res,y_res=smote.fit_resample(X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf564a-d66d-494b-b4e8-b496f0dafc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty=None)\n",
    "xgb=XGBClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "## fit the model\n",
    "rf.fit(X_res,y_res)\n",
    "xgb.fit(X_res,y_res)\n",
    "log_reg.fit(X_res,y_res)\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645332c-1002-402b-827b-9ba8d738ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "cutoff = 0.9\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(validate_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_validate)/len(y_validate), \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a18d0-1218-4b3f-9940-cdbf2bdba115",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "cutoff = 0.1\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(test_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_test)/len(y_test), \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446ee08-11a3-4b47-bc1f-984968c8027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Manually duplicating fraud data points to deal with class imbalance\n",
    "dupe=train_features.copy()\n",
    "dupe['Label']=y_train\n",
    "dupe=dupe[dupe.Label==1]\n",
    "dupe=dupe.drop('Label',axis=1)\n",
    "dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1dc05b-4282-4baa-84f1-89e64ba17046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_dupe=train_features.copy()\n",
    "for i in range(10):\n",
    "    train_features_dupe=pd.concat([train_features_dupe,dupe])\n",
    "train_features_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc01e3-c2be-48ea-aa07-558ddae78463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dupe=np.append(y_train,np.ones(len(train_features_dupe)-len(train_features)))\n",
    "y_train_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0364fda-39a0-410d-bf73-dcb00195c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dupe=StandardScaler().fit_transform(train_features_dupe.values)\n",
    "## fit the model\n",
    "rf.fit(X_dupe,y_train_dupe)\n",
    "xgb.fit(X_dupe,y_train_dupe)\n",
    "log_reg.fit(X_dupe,y_train_dupe)\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3f875-a0ae-4bb1-aabd-c156093388f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Validation\n",
    "cutoff = 0.5\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(validate_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_validate)/len(y_validate), \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63884b74-845f-4af1-914e-3415431b6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "cutoff = 0.5\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(test_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_test)/len(y_test), \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17dd93-cc9d-42e3-8f09-40906714c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Manually downsampling the the non-fraud data points to deal with class imabalance\n",
    "features_down=train_features.sample(n=20000,random_state=1)\n",
    "y_train_down=total_data[0:1000000]['Label'].values[features_down.index]\n",
    "train_down=pd.concat([features_down,dupe],ignore_index=True)\n",
    "y_down=np.append(y_train_down,np.ones(len(train_down)-20000))\n",
    "plt.hist(y_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9483532-1255-4e37-9a48-c12c1d205eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_down=StandardScaler().fit_transform(train_down.values)\n",
    "## fit the model\n",
    "rf.fit(X_down,y_down)\n",
    "xgb.fit(X_down,y_down)\n",
    "log_reg.fit(X_down,y_down)\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b913b-531e-4f3d-9a8a-b01c5a62f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Validation\n",
    "cutoff = 0.5\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(validate_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_validate)/len(y_validate), \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(validate_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_validate)/len(y_validate),  \"and PR AUC is\", average_precision_score(y_validate,y_pred))\n",
    "print(classification_report(y_validate, y_pred))\n",
    "cm = confusion_matrix(y_validate, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d6ae2-2dce-47be-ae7d-4c9cd6aacc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test\n",
    "cutoff = 0.5\n",
    "## store the predicted probabilities\n",
    "y_prob = log_reg.predict_proba(StandardScaler().fit_transform(test_features.values))[:,1]\n",
    "## assign the value based on the cutoff\n",
    "y_pred = 1*(y_prob >= cutoff)\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Logistic Regression with a cutoff of\",cutoff,\n",
    "      \"is\", np.sum(y_pred == y_test)/len(y_test), \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {log_reg.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=xgb.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for XGBoost is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {xgb.__class__.__name__}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=rf.predict(StandardScaler().fit_transform(test_features.values))\n",
    "## print the accuracy\n",
    "## input the accuracy after \"is\",\n",
    "print(\"The training accuracy for Random Forest is\", np.sum(y_pred == y_test)/len(y_test),  \"and PR AUC is\", average_precision_score(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for {rf.__class__.__name__}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645367a-5191-49a3-9c0d-a426bfa5cc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing PCA experiment\n",
    "# Standardize the data\n",
    "scaled_data = StandardScaler().fit_transform(train_features)\n",
    "\n",
    "# Apply PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_data)    \n",
    "\n",
    "# Transform the data\n",
    "transformed_data = pca.transform(scaled_data)\n",
    "\n",
    "print(\"Original data:\\n\", train_features)\n",
    "print(\"\\nScaled data:\\n\", scaled_data)\n",
    "print(\"\\nTransformed data (2 principal components):\\n\", transformed_data)\n",
    "print(\"\\nExplained variance ratio per component:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", np.sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee7084-211b-4698-9de7-ccd77601e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first two PCA components\n",
    "pca_df = pd.DataFrame(data=transformed_data, columns=['PC1', 'PC2'])\n",
    "pca_df['target'] = y_train\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='target',\n",
    "    title='Interactive 3D PCA of Transaction Dataset'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed3079-e38e-49d2-90f7-e58e7e1ac65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Experimenting with LDA for seperating the data\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_lda = lda.fit_transform(train_features, y_train)\n",
    "print(X_lda.shape)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(X_lda[y_train == 0], bins=20, alpha=0.7, label='Class 0')\n",
    "plt.hist(X_lda[y_train == 1], bins=20, alpha=0.7, label='Class 1')\n",
    "plt.title('LDA Projection onto 1D')\n",
    "plt.xlabel('Linear Discriminant')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0413b-3765-49cc-9a08-a859cd624aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Looking at the correlation matrix for our features in our training data\n",
    "corr_matrix = pd.concat([train_features,total_data[:1000000]['Label']],axis=1).corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:erdos_ds_environment]",
   "language": "python",
   "name": "conda-env-erdos_ds_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
